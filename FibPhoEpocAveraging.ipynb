{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example goes through fiber photometry analysis using techniques \n",
    "such as data smoothing, bleach detrending, and z-score analysis. \n",
    "The epoch averaging was done using TDTfilter.\n",
    "\n",
    "Author Contributions: \n",
    "TDT, David Root, and the Morales Lab contributed to the writing and/or conceptualization of the code. \n",
    "The signal processing pipeline was inspired by the workflow developed by David Barker et al. (2017) for the Morales Lab. \n",
    "The data used in the example were provided by David Root.\n",
    "\n",
    "Author Information: \n",
    "David H. Root \n",
    "Assistant Professor \n",
    "Department of Psychology & Neuroscience \n",
    "University of Colorado, Boulder \n",
    "Lab Website: https://www.root-lab.org \n",
    "david.root@colorado.edu\n",
    "\n",
    "About the authors: \n",
    "The Root lab and Morales lab investigate the neurobiology of reward, aversion, addiction, and depression.\n",
    "\n",
    "TDT edits all user submissions in coordination with the contributing\n",
    "author(s) prior to publishing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Front Matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo data ready\n",
      "read from t=0s to t=583.86s\n"
     ]
    }
   ],
   "source": [
    "# magic for Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "#import the read_block function from the tdt package\n",
    "#also import other python packages we care about\n",
    "import numpy as np\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt  # standard Python plotting library\n",
    "import scipy.stats as stats\n",
    "\n",
    "from tdt import read_block, epoc_filter, download_demo_data\n",
    "\n",
    "#%% Importing the Data\n",
    "download_demo_data()\n",
    "BLOCKPATH = 'data/FiPho-180416'\n",
    "data = read_block(BLOCKPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter has a bug that requires import of matplotlib outside of cell with \n",
    "# matplotlib inline magic to properly apply rcParams\n",
    "import matplotlib \n",
    "matplotlib.rcParams['font.size'] = 16 #set font size for all plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the variables for the data you want to extract\n",
    "We will extract two different stream stores surrounding the 'PtAB' epoch event. We are interested in a specific event code for the shock onset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read from t=0s to t=583.86s\n"
     ]
    }
   ],
   "source": [
    "REF_EPOC = 'PtAB' #event store name. This holds behavioral codes that are \n",
    "# read through ports A & B on the front of the RZ\n",
    "SHOCK_CODE = [64959] #shock onset event code we are interested in\n",
    "\n",
    "# make some variables up here to so if they change in new recordings you won't\n",
    "# have to change everything downstream\n",
    "ISOS = '_4054' # 405nm channel. Formally STREAM_STORE1 in maltab example\n",
    "GCaMP = '_4654' # 465nm channel. Formally STREAM_STORE2 in maltab example\n",
    "TRANGE = [-10, 20] # window size [start time relative to epoc onset, window duration]\n",
    "BASELINE_PER = [-10, -6] # baseline period within our window\n",
    "ARTIFACT = float(\"inf\") # optionally set an artifact rejection level\n",
    "\n",
    "#call read block - new variable 'data' is the full data structure\n",
    "data = read_block(BLOCKPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use epoc_filter to extract data around our epoc event\n",
    "Using the 't' parameter extracts data only from the time range around our epoc event. Use the 'values' parameter to specify allowed values of the REF_EPOC to extract.  For stream events, the chunks of data are stored in cell arrays structured as data.streams[GCaMP].filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = epoc_filter(data, REF_EPOC, t=TRANGE, values=SHOCK_CODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally remove artifacts. If any waveform is above ARTIFACT level, or\n",
    "# below -ARTIFACT level, remove it from the data set.\n",
    "total1 = np.size(data.streams[GCaMP].filtered)\n",
    "total2 = np.size(data.streams[ISOS].filtered)\n",
    "\n",
    "# List comprehension checking if any single array in 2D filtered array is > Artifact or < -Artifact\n",
    "data.streams[GCaMP].filtered = [x for x in data.streams[GCaMP].filtered \n",
    "                                if not np.any(x > ARTIFACT) or np.any(x < -ARTIFACT)]\n",
    "data.streams[ISOS].filtered = [x for x in data.streams[ISOS].filtered \n",
    "                               if not np.any(x > ARTIFACT) or np.any(x < -ARTIFACT)]\n",
    "\n",
    "# Get the total number of rejected arrays\n",
    "bad1 = total1 - np.size(data.streams[GCaMP].filtered)\n",
    "bad2 = total2 - np.size(data.streams[ISOS].filtered)\n",
    "total_artifacts = bad1 + bad2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying a time filter to a uniformly sampled signal means that the length of each segment could vary by one sample. Let's find the minimum length so we can trim the excess off before calculating the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More examples of list comprehensions\n",
    "min1 = np.min([np.size(x) for x in data.streams[GCaMP].filtered])\n",
    "min2 = np.min([np.size(x) for x in data.streams[ISOS].filtered])\n",
    "data.streams[GCaMP].filtered = [x[1:min1] for x in data.streams[GCaMP].filtered]\n",
    "data.streams[ISOS].filtered = [x[1:min2] for x in data.streams[ISOS].filtered]\n",
    "\n",
    "# Downsample and average 10x via a moving window mean\n",
    "N = 10 # Average every 10 samples into 1 value\n",
    "F405 = []\n",
    "F465 = []\n",
    "for lst in data.streams[ISOS].filtered: \n",
    "    small_lst = []\n",
    "    for i in range(0, min2, N):\n",
    "        small_lst.append(np.mean(lst[i:i+N-1])) # This is the moving window mean\n",
    "    F405.append(small_lst)\n",
    "\n",
    "for lst in data.streams[GCaMP].filtered: \n",
    "    small_lst = []\n",
    "    for i in range(0, min1, N):\n",
    "        small_lst.append(np.mean(lst[i:i+N-1]))\n",
    "    F465.append(small_lst)\n",
    "\n",
    "#Create a mean signal, standard error of signal, and DC offset\n",
    "meanF405 = np.mean(F405, axis=0)\n",
    "stdF405 = np.std(F405, axis=0)/np.sqrt(len(data.streams[ISOS].filtered))\n",
    "dcF405 = np.mean(meanF405)\n",
    "meanF465 = np.mean(F465, axis=0)\n",
    "stdF465 = np.std(F465, axis=0)/np.sqrt(len(data.streams[GCaMP].filtered))\n",
    "dcF465 = np.mean(meanF465)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot epoc averaged response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the time vector for each stream store\n",
    "ts1 = TRANGE[0] + np.linspace(1, len(meanF465), len(meanF465))/data.streams[GCaMP].fs*N\n",
    "ts2 = TRANGE[0] + np.linspace(1, len(meanF405), len(meanF405))/data.streams[ISOS].fs*N\n",
    "\n",
    "# Subtract DC offset to get signals on top of one another\n",
    "meanF405 = meanF405 - dcF405\n",
    "meanF465 = meanF465 - dcF465\n",
    "\n",
    "# Start making a figure with 4 subplots\n",
    "# First plot is the 405 and 465 averaged signals\n",
    "fig = plt.figure(figsize=(9, 14))\n",
    "ax0 = fig.add_subplot(411) # work with axes and not current plot (plt.)\n",
    "\n",
    "# Plotting the traces\n",
    "p1, = ax0.plot(ts1, meanF465, linewidth=2, color='green', label='GCaMP')\n",
    "p2, = ax0.plot(ts2, meanF405, linewidth=2, color='blueviolet', label='ISOS')\n",
    "\n",
    "# Plotting standard error bands\n",
    "p3 = ax0.fill_between(ts1, meanF465+stdF465, meanF465-stdF465,\n",
    "                      facecolor='green', alpha=0.2)\n",
    "p4 = ax0.fill_between(ts2, meanF405+stdF405, meanF405-stdF405,\n",
    "                      facecolor='blueviolet', alpha=0.2)\n",
    "\n",
    "# Plotting a line at t = 0\n",
    "p5 = ax0.axvline(x=0, linewidth=3, color='slategray', label='Shock Onset')\n",
    "\n",
    "# Finish up the plot\n",
    "ax0.set_xlabel('Seconds')\n",
    "ax0.set_ylabel('mV')\n",
    "ax0.set_title('Foot Shock Response, %i Trials (%i Artifacts Removed)'\n",
    "              % (len(data.streams[GCaMP].filtered), total_artifacts))\n",
    "ax0.legend(handles=[p1, p2, p5], loc='upper right')\n",
    "ax0.set_ylim(min(np.min(meanF465-stdF465), np.min(meanF405-stdF405)),\n",
    "             max(np.max(meanF465+stdF465), np.max(meanF405+stdF405)))\n",
    "ax0.set_xlim(TRANGE[0], TRANGE[1]+TRANGE[0]);\n",
    "\n",
    "plt.close() # Jupyter cells will output any figure calls made, so if you don't want to see it just yet, close existing axis\n",
    "            # https://stackoverflow.com/questions/18717877/prevent-plot-from-showing-in-jupyter-notebook\n",
    "            # Note that this is not good code practice - Jupyter lends it self to these types of bad workarounds "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting 405 channel onto 465 channel to detrend signal bleaching\n",
    "Scale and fit data. Algorithm sourced from Tom Davidson's Github:\n",
    "https://github.com/tjd2002/tjd-shared-code/blob/master/matlab/photometry/FP_normalize.m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_fit_all = []\n",
    "Y_dF_all = []\n",
    "for x, y in zip(F405, F465):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    bls = np.polyfit(x, y, 1)\n",
    "    fit_line = np.multiply(bls[0], x) + bls[1]\n",
    "    Y_fit_all.append(fit_line)\n",
    "    Y_dF_all.append(y-fit_line)\n",
    "\n",
    "# Getting the z-score and standard error\n",
    "zall = []\n",
    "for dF in Y_dF_all: \n",
    "   ind = np.where((np.array(ts2)<BASELINE_PER[1]) & (np.array(ts2)>BASELINE_PER[0]))\n",
    "   zb = np.mean(dF[ind])\n",
    "   zsd = np.std(dF[ind])\n",
    "   zall.append((dF - zb)/zsd)\n",
    "   \n",
    "zerror = np.std(zall, axis=0)/np.sqrt(np.size(zall, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heat Map based on z score of 405 fit subtracted 465"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = fig.add_subplot(412)\n",
    "cs = ax1.imshow(zall, cmap=plt.cm.Greys, interpolation='none', aspect=\"auto\",\n",
    "                extent=[TRANGE[0], TRANGE[1]+TRANGE[0], 0, len(data.streams[GCaMP].filtered)])\n",
    "cbar = fig.colorbar(cs, pad=0.01, fraction=0.02)\n",
    "\n",
    "ax1.set_title('Individual z-Score Traces')\n",
    "ax1.set_ylabel('Trials')\n",
    "ax1.set_xlabel('Seconds from Shock Onset')\n",
    "\n",
    "plt.close() # Suppress figure output again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the z-score trace for the 465 with std error bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax2 = fig.add_subplot(413)\n",
    "p6 = ax2.plot(ts2, np.mean(zall, axis=0), linewidth=2, color='green', label='GCaMP')\n",
    "p7 = ax2.fill_between(ts1, np.mean(zall, axis=0)+zerror\n",
    "                      ,np.mean(zall, axis=0)-zerror, facecolor='green', alpha=0.2)\n",
    "p8 = ax2.axvline(x=0, linewidth=3, color='slategray', label='Shock Onset')\n",
    "ax2.set_ylabel('z-Score')\n",
    "ax2.set_xlabel('Seconds')\n",
    "ax2.set_xlim(TRANGE[0], TRANGE[1]+TRANGE[0])\n",
    "ax2.set_title('Foot Shock Response')\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantify changes as an area under the curve for cue (-5 sec) vs shock (0 sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC = [] # cue, shock\n",
    "ind1 = np.where((np.array(ts2)<-3) & (np.array(ts2)>-5))\n",
    "AUC1= auc(ts2[ind1], np.mean(zall, axis=0)[ind1])\n",
    "ind2 = np.where((np.array(ts2)>0) & (np.array(ts2)<2))\n",
    "AUC2= auc(ts2[ind2], np.mean(zall, axis=0)[ind2])\n",
    "AUC.append(AUC1)\n",
    "AUC.append(AUC2)\n",
    "\n",
    "# Run a two-sample T-test\n",
    "t_stat,p_val = stats.ttest_ind(np.mean(zall, axis=0)[ind1],\n",
    "                               np.mean(zall, axis=0)[ind2], equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax3 = fig.add_subplot(414)\n",
    "p9 = ax3.bar(np.arange(len(AUC)), AUC, color=[.8, .8, .8], align='center', alpha=0.5)\n",
    "\n",
    "# statistical annotation\n",
    "x1, x2 = 0, 1 # columns indices for labels\n",
    "y, h, col = max(AUC) + 2, 2, 'k'\n",
    "ax3.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1.5, c=col)\n",
    "p10 = ax3.text((x1+x2)*.5, y+h, \"*\", ha='center', va='bottom', color=col)\n",
    "\n",
    "# Finish up the plot\n",
    "ax3.set_ylim(0,y+2*h)\n",
    "ax3.set_ylabel('AUC')\n",
    "ax3.set_title('Cue vs Shock Response Changes')\n",
    "ax3.set_xticks(np.arange(-1, len(AUC)+1))\n",
    "ax3.set_xticklabels(['','Cue','Shock',''])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
